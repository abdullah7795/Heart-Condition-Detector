{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe283e0f-67c4-46f9-a506-51c4bee82736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91282914-2f6e-4a76-babb-e97d0b3bf22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy audio chunks shape: (42382, 10000)\n",
      "Unhealthy audio chunks shape: (13934, 10000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "healthy_processed_audio = np.load(\"healthy_processed_audio.npy\", allow_pickle=True)\n",
    "unhealthy_processed_audio = np.load(\"unhealthy_processed_audio.npy\", allow_pickle=True)\n",
    "\n",
    "print(\"Healthy audio chunks shape:\", healthy_processed_audio.shape)\n",
    "print(\"Unhealthy audio chunks shape:\", unhealthy_processed_audio.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "163292f7-71d5-489f-b641-3e8337bf93f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features for Healthy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting MFCCs: 100%|██████████████████| 42382/42382 [04:21<00:00, 162.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features for Unhealthy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting MFCCs: 100%|██████████████████| 13934/13934 [01:19<00:00, 175.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.859375\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91      8477\n",
      "           1       0.76      0.63      0.69      2787\n",
      "\n",
      "    accuracy                           0.86     11264\n",
      "   macro avg       0.82      0.78      0.80     11264\n",
      "weighted avg       0.85      0.86      0.85     11264\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[7932  545]\n",
      " [1039 1748]]\n"
     ]
    }
   ],
   "source": [
    "def extract_features(audio_chunks, sr=22050, n_mfcc=13):\n",
    "    features = []\n",
    "    for y in tqdm(audio_chunks, desc=\"Extracting MFCCs\"):\n",
    "        # Extract MFCCs\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        mfcc_mean = np.mean(mfcc, axis=1)\n",
    "        mfcc_std = np.std(mfcc, axis=1)\n",
    "        feature_vector = np.concatenate([mfcc_mean, mfcc_std])\n",
    "        features.append(feature_vector)\n",
    "    return np.array(features)\n",
    "\n",
    "# 1. Extract features\n",
    "print(\"Extracting features for Healthy...\")\n",
    "X_healthy = extract_features(healthy_processed_audio)\n",
    "\n",
    "print(\"Extracting features for Unhealthy...\")\n",
    "X_unhealthy = extract_features(unhealthy_processed_audio)\n",
    "\n",
    "X = np.vstack([X_healthy, X_unhealthy])\n",
    "y = np.array([0]*len(X_healthy) + [1]*len(X_unhealthy))  # 0=healthy, 1=unhealthy\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f3b17e3-cea6-4095-b9db-fdda1740820b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression (class_weight balanced) ===\n",
      "Accuracy: 0.8425071022727273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.84      0.89      8477\n",
      "           1       0.64      0.85      0.73      2787\n",
      "\n",
      "    accuracy                           0.84     11264\n",
      "   macro avg       0.79      0.85      0.81     11264\n",
      "weighted avg       0.87      0.84      0.85     11264\n",
      "\n",
      "Confusion Matrix:\n",
      " [[7110 1367]\n",
      " [ 407 2380]]\n",
      "\n",
      "=== Logistic Regression with SMOTE Oversampling ===\n",
      "Accuracy: 0.8440163352272727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.84      0.89      8477\n",
      "           1       0.64      0.85      0.73      2787\n",
      "\n",
      "    accuracy                           0.84     11264\n",
      "   macro avg       0.79      0.85      0.81     11264\n",
      "weighted avg       0.87      0.84      0.85     11264\n",
      "\n",
      "Confusion Matrix:\n",
      " [[7130 1347]\n",
      " [ 410 2377]]\n",
      "\n",
      "=== Logistic Regression with Undersampling ===\n",
      "Accuracy: 0.8427734375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.84      0.89      8477\n",
      "           1       0.64      0.86      0.73      2787\n",
      "\n",
      "    accuracy                           0.84     11264\n",
      "   macro avg       0.79      0.85      0.81     11264\n",
      "weighted avg       0.87      0.84      0.85     11264\n",
      "\n",
      "Confusion Matrix:\n",
      " [[7110 1367]\n",
      " [ 404 2383]]\n"
     ]
    }
   ],
   "source": [
    "# Because the dataset is imbalanced, we will explore different techniques to address it.\n",
    "\n",
    "# -----------------------------\n",
    "#  Just use class_weight=\"balanced\"\n",
    "# -----------------------------\n",
    "clf_balanced = LogisticRegression(max_iter=1000, class_weight=\"balanced\")\n",
    "clf_balanced.fit(X_train, y_train)\n",
    "\n",
    "y_pred_balanced = clf_balanced.predict(X_test)\n",
    "\n",
    "print(\"\\n=== Logistic Regression (class_weight balanced) ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_balanced))\n",
    "print(classification_report(y_test, y_pred_balanced))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_balanced))\n",
    "\n",
    "# -----------------------------\n",
    "# Apply SMOTE (oversampling)\n",
    "# -----------------------------\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "clf_smote = LogisticRegression(max_iter=1000)\n",
    "clf_smote.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "y_pred_smote = clf_smote.predict(X_test)\n",
    "\n",
    "print(\"\\n=== Logistic Regression with SMOTE Oversampling ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_smote))\n",
    "print(classification_report(y_test, y_pred_smote))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_smote))\n",
    "\n",
    "# -----------------------------\n",
    "# Apply undersampling\n",
    "# -----------------------------\n",
    "undersample = RandomUnderSampler(random_state=42)\n",
    "X_train_us, y_train_us = undersample.fit_resample(X_train, y_train)\n",
    "\n",
    "clf_us = LogisticRegression(max_iter=1000)\n",
    "clf_us.fit(X_train_us, y_train_us)\n",
    "\n",
    "y_pred_us = clf_us.predict(X_test)\n",
    "\n",
    "print(\"\\n=== Logistic Regression with Undersampling ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_us))\n",
    "print(classification_report(y_test, y_pred_us))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_us))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dff02f7-6554-4097-8b5d-b768ee6d65ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Random Forest ===\n",
      "Accuracy: 0.9627130681818182\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97      8477\n",
      "           1       0.90      0.96      0.93      2787\n",
      "\n",
      "    accuracy                           0.96     11264\n",
      "   macro avg       0.94      0.96      0.95     11264\n",
      "weighted avg       0.96      0.96      0.96     11264\n",
      "\n",
      "Confusion Matrix:\n",
      " [[8175  302]\n",
      " [ 118 2669]]\n",
      "\n",
      "=== XGBoost ===\n",
      "Accuracy: 0.9818892045454546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      8477\n",
      "           1       0.95      0.98      0.96      2787\n",
      "\n",
      "    accuracy                           0.98     11264\n",
      "   macro avg       0.97      0.98      0.98     11264\n",
      "weighted avg       0.98      0.98      0.98     11264\n",
      "\n",
      "Confusion Matrix:\n",
      " [[8333  144]\n",
      " [  60 2727]]\n"
     ]
    }
   ],
   "source": [
    "# === Random Forest ===\n",
    "print(\"\\n=== Random Forest ===\")\n",
    "clf_rf = RandomForestClassifier(\n",
    "    n_estimators=300,       # number of trees\n",
    "    max_depth=20,           # limit tree depth\n",
    "    min_samples_split=10,   # split only if enough samples\n",
    "    min_samples_leaf=5,     # prevent overfitting on small leaves\n",
    "    class_weight=\"balanced\",# handle imbalance\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "clf_rf.fit(X_train, y_train)\n",
    "y_pred_rf = clf_rf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
    "\n",
    "# === XGBoost ===\n",
    "print(\"\\n=== XGBoost ===\")\n",
    "clf_xgb = XGBClassifier(\n",
    "    n_estimators=400,         # number of boosting rounds\n",
    "    max_depth=8,              # tree depth\n",
    "    learning_rate=0.05,       # smaller LR with more estimators\n",
    "    subsample=0.8,            # random subsampling for robustness\n",
    "    colsample_bytree=0.8,     # feature subsampling\n",
    "    scale_pos_weight=len(y_train[y_train==0]) / len(y_train[y_train==1]), # handle imbalance\n",
    "    eval_metric=\"logloss\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "clf_xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = clf_xgb.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4585b52-124a-4d37-9b65-fdc9093db4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"LogReg\": (accuracy_score(y_test, y_pred), classification_report(y_test, y_pred, output_dict=True)),\n",
    "    \"RandomForest\": (accuracy_score(y_test, y_pred_rf), classification_report(y_test, y_pred_rf, output_dict=True)),\n",
    "    \"XGBoost\": (accuracy_score(y_test, y_pred_xgb), classification_report(y_test, y_pred_xgb, output_dict=True)),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8317a7d6-d9f4-494a-9501-1064a9dc19b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to xgboost_heart_sound_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Path to save the model\n",
    "model_path = \"xgboost_heart_sound_model.pkl\"\n",
    "\n",
    "# Save the trained XGBoost model\n",
    "joblib.dump(clf_xgb, model_path)\n",
    "print(f\"Model saved to {model_path}\")\n",
    "scaler_path = \"scaler_heart_sound.pkl\"\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f\"Scaler saved to {scaler_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5918fe38-6a40-4f8b-af2d-8408ceef4a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
